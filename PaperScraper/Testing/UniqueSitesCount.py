from PaperScraper import PaperScraper
from pprint import pprint
pmids = """25355699
9333048
9303390
24953566
12006516
16258082
7505268
22080439
22864522
24965808
25739672
18242722
23358650
11709329
21986846
17308894
21833442
25304209
25403217
20876255
9669400
10942366
8683227
7687326
26847057
20305636
25049380
18056191
23564374
19575282
19559353
22723563
9521260
9916886
19147776
21282541
23648237
23397498
17908979
15701859
16012793
17578973
12459665
25915168
21931661
24962521
23543270
11896118
23828252
23204544
23138441
22968523
20592725
22584230
23103659
20937945
23602721
15173077
19633055
25267761
25267741
15820947
17122578
22941375
25709442
20308665
22648179
20421541
24602182
17328081
9815694
14513369
23274395
18794097
24290734
16489081
20801016
19604121
16520660
11127949
23763920
16619562
1428729
22178041
15187995
12904897
12237769
15150611
14998859
22370972
1756260
17962427
17699350
20809205
23975704
21285987
16809800
18500375
18524995
25894719
20943763
17595665
15477860
12833461
25844818
11221967
15711828
15122073
15042679
11870164
15033677
16061865
17520255
19047127
23543270
16278410
25801095
11230473
16144928
12228203
18049336
17909807
21242495
11335787
17308894
8770969
15049795
18388122
19251941
23112576
19190127
22753910
11297238
23609015
12944598
21483158
8061425
19477353
17438100
15362960
17941902
15080776
23651793
10372717
17289896
15150584
19190127
11935212
12201498
11308249
14731323
1675263
2871137
1355523
2568175
2887641
2882837
18414864
8093854
8098059
8094996
7912725
18791718
18791717
21704241
15531008
22558101
23319864
11390726
17101999
24569464
16774958
10496388
10721954
21863338
21311578
21505316
22067666
19823111
17379048
23530878
10952488
10577851
23619698
14711981"""
ps = PaperScraper()

#pprint(ps.extract_from_url("https://www.sciencedirect.com/science/article/pii/S0144861713011806?via%3Dihub"))

site_count = {}
for pmid in pmids.split("\n"):
    #pprint(site_count)
    try:
        sites = ps.get_sites_from_pmid(pmid)
        for site in sites:
            domain = site.split("/")[2]
            if domain in site_count.keys():
                site_count[domain].append(site)
            else:
                site_count[domain] = []
                site_count[domain].append(site)
        for key in sorted(site_count, key=lambda k: len(site_count[k]), reverse=True):
            print(key + ": " + str(len(site_count.get(key))))
        print("\n\n")
    except IOError:
        pass
